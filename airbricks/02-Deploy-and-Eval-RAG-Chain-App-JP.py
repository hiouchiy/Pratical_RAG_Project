# Databricks notebook source
# MAGIC %md 
# MAGIC ### ç’°å¢ƒ
# MAGIC - ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—: ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ã€ã¾ãŸã¯ã€15.4 ML LTS

# COMMAND ----------

# MAGIC %md-sandbox
# MAGIC # RAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆï¼ãƒ‡ãƒ—ãƒ­ã‚¤ï¼è©•ä¾¡
# MAGIC
# MAGIC å‰å›ã®[01-Data-Preparation-and-Index]($./01-Data-Preparation-and-Index [DO NOT EDIT])ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã€RAGã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«å¿…è¦ãªä»¥ä¸‹ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’æº–å‚™ã—ã¾ã—ãŸã€‚
# MAGIC - FAQãƒ‡ãƒ¼ã‚¿ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (Embeddingãƒ¢ãƒ‡ãƒ«å«ã‚€)
# MAGIC - æ–‡ç« ç”ŸæˆLLMï¼ˆLlama3.1-70Bï¼‰ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# MAGIC
# MAGIC ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€Mosaic AI Agent Frameworkã‚’ä½¿ç”¨ã—ã¦ã€ã“ã‚Œã‚‰ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ç¹‹ãåˆã‚ã›ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ã«é©åˆ‡ã«å›ç­”ã™ã‚‹ RAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¢ãƒ—ãƒªï¼ˆãƒã‚§ãƒ¼ãƒ³ã‚„ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã¨ã‚‚å‘¼ã°ã‚Œã‚‹ï¼‰ã‚’ä½œæˆã—ã€ãã‚Œã‚’ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™ã€‚
# MAGIC
# MAGIC ã•ã‚‰ã«ã€Mosaic AI Agent Evaluationã‚’ä½¿ç”¨ã—ã¦ã€RAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¢ãƒ—ãƒªã®è©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚

# COMMAND ----------

# MAGIC %pip install -U -qqqq databricks-agents mlflow mlflow-skinny databricks-vectorsearch langchain==0.2.11 langchain_core==0.2.23 langchain_community==0.2.10 openai
# MAGIC dbutils.library.restartPython()

# COMMAND ----------

# DBTITLE 1,ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆä½¿ç”¨ã—ã¾ã›ã‚“ï¼‰
# MAGIC %pip install --quiet -U databricks-agents==0.1.0 mlflow-skinny==2.14.0 mlflow==2.14.0 mlflow[gateway] langchain==0.2.1 langchain_core==0.2.5 langchain_community==0.2.4 databricks-vectorsearch==0.38 databricks-sdk==0.23.0 openai
# MAGIC dbutils.library.restartPython()

# COMMAND ----------

# DBTITLE 1,ã‚³ãƒ³ãƒ•ã‚£ã‚°(ç’°å¢ƒã«åˆã‚ã›ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ï¼‰
# MAGIC %run ./config

# COMMAND ----------

# MAGIC %md
# MAGIC ### RAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¢ãƒ—ãƒªã§ä½¿ç”¨ã•ã‚Œã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’YAMLãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜

# COMMAND ----------

import yaml
import mlflow

rag_chain_config = {
      "vector_search_endpoint_name": VECTOR_SEARCH_ENDPOINT_NAME,
      "vector_search_index_name": f"{catalog}.{dbName}.{embed_table_name}_vs_index",
      "llm_endpoint_name": instruct_endpoint_name,
}
config_file_name = 'rag_chain_config.yaml'
try:
    with open(config_file_name, 'w') as f:
        yaml.dump(rag_chain_config, f)
except:
    print('pass to work on build job')

# COMMAND ----------

# MAGIC %md
# MAGIC ### RAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè£…ã‚³ãƒ¼ãƒ‰
# MAGIC
# MAGIC Langchainã€ãŠã‚ˆã³ã€pyfunc.PythonModelãƒ™ãƒ¼ã‚¹ã§å®Ÿè£…ã§ãã¾ã™ã€‚
# MAGIC
# MAGIC å®Ÿè£…ã‚³ãƒ¼ãƒ‰ã¯"chain"ãŠã‚ˆã³"chain_pyfunc"ã«ãã‚Œãã‚Œã‚ã‚Šã¾ã™ã€‚

# COMMAND ----------

# MAGIC %md
# MAGIC ### RAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¢ãƒ—ãƒªã‚’Unity Catalogã«ç™»éŒ²

# COMMAND ----------

import os

# Specify the full path to the chain notebook
chain_notebook_path = os.path.join(os.getcwd(), "chain_langchain")

# Specify the full path to the config file (.yaml)
config_file_path = os.path.join(os.getcwd(), "rag_chain_config.yaml")

print(f"Chain notebook path: {chain_notebook_path}")
print(f"Chain notebook path: {config_file_path}")

# COMMAND ----------

user_account_name = dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()

# COMMAND ----------

import mlflow

# Set the experiment name
mlflow.set_experiment(f"/Users/{user_account_name}/airbricks_rag_experiment")

# Log the model to MLflow
# TODO: remove example_no_conversion once this papercut is fixed
with mlflow.start_run(run_name="airbricks_rag_chatbot"):
    # Tag to differentiate from the data pipeline runs
    mlflow.set_tag("type", "chain")

    input_example = {
        "messages": [{"role": "user", "content": "Zenith ZR-450ã®ã‚¿ãƒƒãƒã‚¹ã‚¯ãƒªãƒ¼ãƒ³æ“ä½œãƒ‘ãƒãƒ«ã®åå¿œãŒéˆã„ã§ã™ã€‚ã©ã†ã—ãŸã‚‰è‰¯ã„ã§ã™ã‹ï¼Ÿ"}]
    }

    logged_chain_info = mlflow.langchain.log_model(
        lc_model=chain_notebook_path,  # Chain code file e.g., /path/to/the/chain.py
        model_config=config_file_path,  # Chain configuration set in 00_config
        artifact_path="chain",  # Required by MLflow
        input_example=input_example,  # Save the chain's input schema.  MLflow will execute the chain before logging & capture it's output schema.
        example_no_conversion=True,  # Required by MLflow to use the input_example as the chain's schema
    )

    # # Attach the data pipeline's configuration as parameters
    # mlflow.log_params(_flatten_nested_params({"data_pipeline": data_pipeline_config}))

    # # Attach the data pipeline configuration 
    # mlflow.log_dict(data_pipeline_config, "data_pipeline_config.json")

# COMMAND ----------

# DBTITLE 1,ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆä½¿ç”¨ã—ã¾ã›ã‚“ï¼‰
import numpy as np
import pandas as pd

import mlflow
from mlflow.models import infer_signature

with mlflow.start_run(run_name="airbricks_rag_chatbot"):
  # å…¥å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒã®å®šç¾©
  input_example = {
    "messages": [
        {
            "role": "user",
            "content": "æ–°ã—ã„ã‚¨ã‚¢ã‚³ãƒ³ã‚’é¸ã¶éš›ã«æœ€ã‚‚é‡è¦ãªã“ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        }
    ],
  }

  output_response = {
    'id': 'chatcmpl_e048d1af-4b9c-4cc9-941f-0311ac5aa7ab',
    'choices': [
      {
        'finish_reason': 'stop', 
        'index': 0,
        'logprobs': "",
        'message': {
          'content': 'æ–°ã—ã„ã‚¨ã‚¢ã‚³ãƒ³ã‚’é¸ã¶éš›ã«æœ€ã‚‚é‡è¦ãªã“ã¨ã¯ã€å†·å´èƒ½åŠ›ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡ã€ã‚µã‚¤ã‚ºã€ç‰¹å®šã®æ©Ÿèƒ½ï¼ˆä¾‹ãˆã°ç©ºæ°—æµ„åŒ–ã‚„Wi-Fiæ¥ç¶šï¼‰ãªã©ã€ã”è‡ªå®…ã‚„ã‚ªãƒ•ã‚£ã‚¹ã®ãƒ‹ãƒ¼ã‚ºã«æœ€é©ãªç‰¹æ€§ã‚’è€ƒæ…®ã™ã‚‹ã“ã¨ã§ã™ã€‚',
          'role': 'assistant'
          }
        }
      ],
    'created': 1719722525,
    'model': 'dbrx-instruct-032724',
    'object': 'chat.completion',
    'usage': {'completion_tokens': 279,'prompt_tokens': 1386,'total_tokens': 1665}
  }

  signature = infer_signature(
    model_input=input_example, 
    model_output=output_response)
  
  logged_chain_info = mlflow.pyfunc.log_model(
    python_model=chain_notebook_path,
    model_config=config_file_path,
    artifact_path="chain",
    signature=signature, 
    input_example=input_example,
    example_no_conversion=True,
    pip_requirements=[
      "databricks-agents==0.1.0",
      "langchain==0.2.1",
      "langchain_core==0.2.5",
      "langchain_community==0.2.4",
      "databricks-vectorsearch==0.38",
      "databricks-sdk==0.23.0",
      "openai"]
  )

# COMMAND ----------

chain = mlflow.langchain.load_model(logged_chain_info.model_uri)
chain.invoke(input_example)

# COMMAND ----------

# DBTITLE 1,ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆä½¿ç”¨ã—ã¾ã›ã‚“ï¼‰
# Test the chain locally
chain = mlflow.pyfunc.load_model(logged_chain_info.model_uri)
chain.predict(input_example)

# COMMAND ----------

import mlflow

mlflow.set_registry_uri("databricks-uc")

model_name = f"{catalog}.{dbName}.{registered_model_name}"
uc_model_info = mlflow.register_model(model_uri=logged_chain_info.model_uri, name=model_name)

# COMMAND ----------

### Test the registered model
registered_agent = mlflow.langchain.load_model(f"models:/{model_name}/{uc_model_info.version}")

registered_agent.invoke(input_example)

# COMMAND ----------

# DBTITLE 1,ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆä½¿ç”¨ã—ã¾ã›ã‚“ï¼‰
### Test the registered model
registered_agent = mlflow.pyfunc.load_model(f"models:/{model_name}/{uc_model_info.version}")

registered_agent.predict(input_example)

# COMMAND ----------

# MAGIC %md 
# MAGIC ### RAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¢ãƒ—ãƒªã‚’ã‚µãƒ¼ãƒ“ãƒ³ã‚°ãƒ»ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤
# MAGIC
# MAGIC æœ€å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¢ãƒ—ãƒªã‚’ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã“ã¨ã§ã™ã€‚
# MAGIC Databricks Agentãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
# MAGIC
# MAGIC
# MAGIC ã“ã‚Œã§ã€ãƒã‚§ãƒ¼ãƒ³ã®è©•ä¾¡ã€ãŠã‚ˆã³ã€ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚¢ãƒ—ãƒªã‹ã‚‰ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

# COMMAND ----------

import os
import mlflow
from databricks import agents

deployment_info = agents.deploy(
    model_name, 
    uc_model_info.version 
)

browser_url = mlflow.utils.databricks_utils.get_browser_hostname()
print(f"\n\nView deployment status: https://{browser_url}/ml/endpoints/{deployment_info.endpoint_name}")

review_instructions = """### æ ªå¼ä¼šç¤¾ã‚¨ã‚¢ãƒ–ãƒªãƒƒã‚¯ã‚¹ FAQãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ†ã‚¹ãƒˆæ‰‹é †

ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®å“è³ªå‘ä¸Šã®ãŸã‚ã«ãœã²ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ãã ã•ã„ã€‚

1. **å¤šæ§˜ãªè³ªå•ã‚’ãŠè©¦ã—ãã ã•ã„**ï¼š
   - å®Ÿéš›ã®ãŠå®¢æ§˜ãŒå°‹ã­ã‚‹ã¨äºˆæƒ³ã•ã‚Œã‚‹å¤šæ§˜ãªè³ªå•ã‚’å…¥åŠ›ãã ã•ã„ã€‚ã“ã‚Œã¯ã€äºˆæƒ³ã•ã‚Œã‚‹è³ªå•ã‚’åŠ¹æœçš„ã«å‡¦ç†ã§ãã‚‹ã‹å¦ã‹ã‚’ç¢ºèªã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚

2. **å›ç­”ã«å¯¾ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**ï¼š
   - è³ªå•ã®å¾Œã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’ä½¿ã£ã¦ã€ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®å›ç­”ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
   - å›ç­”ãŒé–“é•ã£ã¦ã„ãŸã‚Šã€æ”¹å–„ã™ã¹ãç‚¹ãŒã‚ã‚‹å ´åˆã¯ã€ã€Œå›ç­”ã®ç·¨é›†ï¼ˆEdit Responseï¼‰ã€ã§ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚çš†æ§˜ã®ä¿®æ­£ã«ã‚ˆã‚Šã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ç²¾åº¦ã‚’å‘ä¸Šã§ãã¾ã™ã€‚

3. **å›ç­”ã«ä»˜éšã—ã¦ã„ã‚‹å‚è€ƒæ–‡çŒ®ã®ç¢ºèª**ï¼š
   - è³ªå•ã«å¯¾ã—ã¦ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å›ç­”ã•ã‚Œã‚‹å„å‚è€ƒæ–‡çŒ®ã‚’ã”ç¢ºèªãã ã•ã„ã€‚
   - GoodğŸ‘ï¼BadğŸ‘æ©Ÿèƒ½ã‚’ä½¿ã£ã¦ã€ãã®æ–‡æ›¸ãŒè³ªå•å†…å®¹ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’è©•ä¾¡ãã ã•ã„ã€‚

ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®è©•ä¾¡ã«ãŠæ™‚é–“ã‚’å‰²ã„ã¦ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é«˜å“è³ªã®è£½å“ã‚’ãŠå±Šã‘ã™ã‚‹ãŸã‚ã«ã¯ã€çš†æ§˜ã®ã”å”åŠ›ãŒä¸å¯æ¬ ã§ã™ã€‚"""

agents.set_review_instructions(model_name, review_instructions)

# COMMAND ----------

# DBTITLE 1,ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆä½¿ç”¨ã—ã¾ã›ã‚“ï¼‰
import os
import mlflow
from databricks import agents

deployment_info = agents.deploy(
    model_name, 
    uc_model_info.version, 
    environment_vars={
        "DATABRICKS_TOKEN": "{{secrets/"+databricks_token_secrets_scope+"/"+databricks_token_secrets_key+"}}"
    })

browser_url = mlflow.utils.databricks_utils.get_browser_hostname()
print(f"\n\nView deployment status: https://{browser_url}/ml/endpoints/{deployment_info.endpoint_name}")

review_instructions = """### æ ªå¼ä¼šç¤¾ã‚¨ã‚¢ãƒ–ãƒªãƒƒã‚¯ã‚¹ FAQãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ†ã‚¹ãƒˆæ‰‹é †

ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®å“è³ªå‘ä¸Šã®ãŸã‚ã«ãœã²ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ãã ã•ã„ã€‚

1. **å¤šæ§˜ãªè³ªå•ã‚’ãŠè©¦ã—ãã ã•ã„**ï¼š
   - å®Ÿéš›ã®ãŠå®¢æ§˜ãŒå°‹ã­ã‚‹ã¨äºˆæƒ³ã•ã‚Œã‚‹å¤šæ§˜ãªè³ªå•ã‚’å…¥åŠ›ãã ã•ã„ã€‚ã“ã‚Œã¯ã€äºˆæƒ³ã•ã‚Œã‚‹è³ªå•ã‚’åŠ¹æœçš„ã«å‡¦ç†ã§ãã‚‹ã‹å¦ã‹ã‚’ç¢ºèªã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚

2. **å›ç­”ã«å¯¾ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**ï¼š
   - è³ªå•ã®å¾Œã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’ä½¿ã£ã¦ã€ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®å›ç­”ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
   - å›ç­”ãŒé–“é•ã£ã¦ã„ãŸã‚Šã€æ”¹å–„ã™ã¹ãç‚¹ãŒã‚ã‚‹å ´åˆã¯ã€ã€Œå›ç­”ã®ç·¨é›†ï¼ˆEdit Responseï¼‰ã€ã§ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚çš†æ§˜ã®ä¿®æ­£ã«ã‚ˆã‚Šã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ç²¾åº¦ã‚’å‘ä¸Šã§ãã¾ã™ã€‚

3. **å›ç­”ã«ä»˜éšã—ã¦ã„ã‚‹å‚è€ƒæ–‡çŒ®ã®ç¢ºèª**ï¼š
   - è³ªå•ã«å¯¾ã—ã¦ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å›ç­”ã•ã‚Œã‚‹å„å‚è€ƒæ–‡çŒ®ã‚’ã”ç¢ºèªãã ã•ã„ã€‚
   - GoodğŸ‘ï¼BadğŸ‘æ©Ÿèƒ½ã‚’ä½¿ã£ã¦ã€ãã®æ–‡æ›¸ãŒè³ªå•å†…å®¹ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’è©•ä¾¡ãã ã•ã„ã€‚

ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®è©•ä¾¡ã«ãŠæ™‚é–“ã‚’å‰²ã„ã¦ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é«˜å“è³ªã®è£½å“ã‚’ãŠå±Šã‘ã™ã‚‹ãŸã‚ã«ã¯ã€çš†æ§˜ã®ã”å”åŠ›ãŒä¸å¯æ¬ ã§ã™ã€‚"""

agents.set_review_instructions(model_name, review_instructions)

# COMMAND ----------

import time
from databricks.sdk import WorkspaceClient
from databricks.sdk.service.serving import EndpointStateReady, EndpointStateConfigUpdate
from databricks.sdk.errors import NotFound, ResourceDoesNotExist

# Wait for the Review App to be ready
print("\nWaiting for endpoint to deploy.  This can take 15 - 20 minutes.", end="")
w = WorkspaceClient()
while w.serving_endpoints.get(deployment_info.endpoint_name).state.ready == EndpointStateReady.NOT_READY or w.serving_endpoints.get(deployment_info.endpoint_name).state.config_update == EndpointStateConfigUpdate.IN_PROGRESS:
    print(".", end="")
    time.sleep(30)

print(f"\n\nReview App: {deployment_info.review_app_url}")

# COMMAND ----------

# MAGIC %md
# MAGIC ### Mosaic AI Agent Evaluationã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ—ãƒªã‚’ä½¿ç”¨ã—ã¦äººæ‰‹ã§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¡Œã†
# MAGIC é–¢ä¿‚è€…ã«Mosaic AI Agent Evaluation ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ—ãƒª ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©ã‚’ä¸ãˆã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¡Œã£ã¦ã‚‚ã‚‰ã„ã¾ã—ã‚‡ã†ã€‚
# MAGIC ã‚¢ã‚¯ã‚»ã‚¹ã‚’ç°¡å˜ã«ã™ã‚‹ãŸã‚ã€é–¢ä¿‚è€…ã¯Databricksã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’æŒã£ã¦ã„ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

# COMMAND ----------

from databricks import agents

user_list = ["someone@databricks.com"]
agents.set_permissions(model_name=model_name, users=user_list, permission_level=agents.PermissionLevel.CAN_QUERY)

print(f"Share this URL with your stakeholders: {deployment_info.review_app_url}")

# COMMAND ----------

# MAGIC %md
# MAGIC ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ‡ãƒ—ãƒ­ã‚¤çŠ¶æ³ã¯[Serving Endpoint UI](#/mlflow/endpoints)ã§ç¢ºèªã§ãã¾ã™ã€‚ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†ã¾ã§æ•°åˆ†ç¨‹åº¦è¦ã—ã¾ã™ã€‚
# MAGIC ãªãŠã€Feedbackã¨ã„ã†ã®ãŒã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ—ãƒªç”¨ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§ã™ã€‚
# MAGIC
# MAGIC ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†å¾Œã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ—ãƒªã®URLã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦äººæ‰‹ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¡Œã„ã¾ã—ã‚‡ã†ã€‚

# COMMAND ----------

# MAGIC %md
# MAGIC ### Mosaic AI Agent Evaluation "LLM-as-a-judge" ã‚’ä½¿ç”¨ã—ã¦RAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è‡ªå‹•è©•ä¾¡ã‚’è¡Œã†
# MAGIC
# MAGIC å‚è€ƒï¼šhttps://docs.databricks.com/en/generative-ai/agent-evaluation/evaluation-set.html

# COMMAND ----------

import mlflow
import pandas as pd
eval_set  = [
    {
      "request_id": "1",
      "request": "Zenith ZR-450ã®ã‚¿ãƒƒãƒã‚¹ã‚¯ãƒªãƒ¼ãƒ³æ“ä½œãƒ‘ãƒãƒ«ã®åå¿œãŒéˆã„ã§ã™ã€‚ã©ã†ã—ãŸã‚‰è‰¯ã„ã§ã™ã‹ï¼Ÿ",
      "expected_retrieved_context": [
        {
            "doc_uri": "https://example.com/1855",
        }
      ],
      "expected_response": "Zenith ZR-450ã®ã‚¿ãƒƒãƒã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãŒéˆã„å ´åˆã®å…·ä½“çš„ãªå¯¾å‡¦æ³•ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š\n	1.	ç”»é¢ã‚’æ¸…æƒã—ã¦ãã ã•ã„ã€‚\n	2.	æ”¹å–„ã—ãªã„å ´åˆã¯ã€ãƒ•ã‚¡ãƒ¼ãƒ ã‚¦ã‚§ã‚¢ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n	3.	ãã‚Œã§ã‚‚è§£æ±ºã—ãªã„å ´åˆã¯ã€ã‚µãƒãƒ¼ãƒˆã‚»ãƒ³ã‚¿ãƒ¼ã«é€£çµ¡ã—ã¦æŠ€è¡“çš„ãªã‚µãƒãƒ¼ãƒˆã‚’å—ã‘ã¦ãã ã•ã„ã€‚\n\nã“ã¡ã‚‰ãŒæ­£ã—ã„å¯¾å¿œæ‰‹é †ã¨ãªã‚Šã¾ã™ã€‚"
    },
    {
      "request_id": "2",
      "request": "ã‚¨ã‚¢ã‚³ãƒ³ã‚’è²·ã„æ›ãˆã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®åˆ¤æ–­åŸºæº–ã¯ä½•ã§ã™ã‹ï¼Ÿ",
      "expected_retrieved_context": [
        {
            "doc_uri": "https://example.com/8321",
        },
        {
            "doc_uri": "https://example.com/3029",
        },
        {
            "doc_uri": "https://example.com/3724",
        },
        {
            "doc_uri": "https://example.com/2849",
        }
      ],
      "expected_response": "ã‚¨ã‚¢ã‚³ãƒ³ã‚’è²·ã„æ›ãˆã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®åˆ¤æ–­åŸºæº–ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š\n\n	1.	ä½¿ç”¨å¹´æ•°ãŒ10å¹´ä»¥ä¸ŠçµŒéã—ãŸã€‚\n	2.	ä¿®ç†ãŒé »ç¹ã«å¿…è¦ã«ãªã£ãŸã€‚\n	3.	é›»æ°—ä»£ãŒå¢—åŠ ã—ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡ãŒä½ä¸‹ã—ã¦ã„ã‚‹ã€‚\n	4.	æœ€æ–°æŠ€è¡“ã‚„æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ãŸã„ã¨è€ƒãˆã¦ã„ã‚‹å ´åˆã€‚"
    },
    {
      "request_id": "3",
      "request": "ãƒªãƒ“ãƒ³ã‚°ãŒï¼“ï¼å¹³ç±³ãªã®ã§ã™ãŒã€ã©ã®è£½å“ãŒãƒ™ã‚¹ãƒˆï¼Ÿ",
      "expected_retrieved_context": [
        {
            "doc_uri": "https://example.com/9662",
        },
        {
            "doc_uri": "https://example.com/4609",
        },
        {
            "doc_uri": "https://example.com/1885",
        }
      ],
      "expected_response": "30å¹³ç±³ã®ãƒªãƒ“ãƒ³ã‚°ã«é©ã—ãŸã‚¨ã‚¢ã‚³ãƒ³ã¨ã—ã¦ã¯ã€ä»¥ä¸‹ã®è£½å“ãŒå€™è£œã¨ãªã‚Šã¾ã™ï¼š\n\n	1.	EcoSmart TY-700:\n	â€¢	å†·å´èƒ½åŠ›ï¼š7.0 kW\n	â€¢	åºƒã„ç©ºé–“ã«å¯¾å¿œå¯èƒ½ã§ã€åŠ¹ç‡çš„ãªå†·æš–æˆ¿ãŒå¯èƒ½ã§ã™ã€‚\n	2.	Zenith ZR-450:\n	â€¢	å†·å´èƒ½åŠ›ï¼š4.5 kW\n	â€¢	å°‘ã—å°ã•ã‚ã®å†·å´èƒ½åŠ›ã§ã™ãŒã€30å¹³ç±³ç¨‹åº¦ã®éƒ¨å±‹ã«ã¯ååˆ†ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™ã€‚\n\nã„ãšã‚Œã‚‚ã€åºƒã•ã«å¿œã˜ãŸå†·å´èƒ½åŠ›ã‚’æŒã¤ãŸã‚ã€å¥½ã¿ã«å¿œã˜ã¦é¸æŠã§ãã¾ã™ã€‚"
    }
]
#### Convert dictionary to a pandas DataFrame
eval_set_df = pd.DataFrame(eval_set)


model_name = f"{catalog}.{dbName}.{registered_model_name}"

###
# mlflow.evaluate() call
###
# with mlflow.start_run(run_id=logged_chain_info.run_id):
with mlflow.start_run(run_name="new_eval_run"):
  evaluation_results = mlflow.evaluate(
      data=eval_set_df,
      model=f"models:/{model_name}/{uc_model_info.version}",
      model_type="databricks-agent",
  )

# COMMAND ----------

evaluation_results.tables["eval_results"]

# COMMAND ----------

# MAGIC %md
# MAGIC ### æœ€å¾Œã«ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚ŒãŸRAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«RESTã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã¿ã¾ã—ã‚‡ã†

# COMMAND ----------

import requests
import json

data = {
  "messages": [{"role": "user", "content": "ã‚¨ã‚¢ã‚³ãƒ³ã®è²·ã„æ›ãˆã‚’æ±ºã‚ã‚‹éš›ã®åˆ¤æ–­åŸºæº–ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"}]
}

databricks_host = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().get()
databricks_token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()
headers = {"Context-Type": "text/json", "Authorization": f"Bearer {databricks_token}"}

response = requests.post(
    url=f"{databricks_host}/serving-endpoints/{deployment_info.endpoint_name}/invocations", json=data, headers=headers
)

print(response.json()["choices"][0]["message"]["content"])

# COMMAND ----------

# MAGIC %md ## ãŠã¾ã‘ï¼šãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ—ãƒªåã‚’æ¤œç´¢
# MAGIC
# MAGIC ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®çŠ¶æ…‹ã‚’å¤±ã„ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ—ãƒªã®URLã‚’è¦‹ã¤ã‘ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆã¯ã€ã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
# MAGIC
# MAGIC ã¾ãŸã¯ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ—ãƒªã®URLã‚’æ¬¡ã®ã‚ˆã†ã«ä½œæˆã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚
# MAGIC
# MAGIC `https://<your-workspace-url>/ml/reviews/{UC_CATALOG}.{UC_SCHEMA}.{UC_MODEL_NAME}/{UC_MODEL_VERSION_NUMBER}/instructions`

# COMMAND ----------

active_deployments = agents.list_deployments()

active_deployment = next((item for item in active_deployments if item.model_name == model_name), None)

print(f"Review App URL: {active_deployment.review_app_url}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ä»¥ä¸Šã§ã™ã€‚
# MAGIC
# MAGIC ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾ã™ã‚‹ãŸã‚ã«ã€æœ¬ã‚µãƒ³ãƒ—ãƒ«ã§ä½œæˆã—ãŸã™ã¹ã¦ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤ãã ã•ã„ã€‚
# MAGIC
