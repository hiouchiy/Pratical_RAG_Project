# Databricks notebook source
# MAGIC %pip install mlflow==2.10.1 lxml==4.9.3 transformers==4.30.2 langchain==0.1.5 databricks-vectorsearch==0.22 databricks-sdk==0.28.0 databricks-feature-store==0.17.0
# MAGIC %pip install dspy-ai -U
# MAGIC dbutils.library.restartPython()

# COMMAND ----------

# MAGIC %run ./config

# COMMAND ----------

# MAGIC %run ../../_resources/00-init $reset_all_data=false

# COMMAND ----------

sql(f"CREATE CATALOG IF NOT EXISTS {catalog};")
sql(f"USE CATALOG {catalog};")
sql(f"CREATE SCHEMA IF NOT EXISTS {dbName};")
sql(f"USE SCHEMA {dbName};")
sql(f"CREATE VOLUME IF NOT EXISTS {volume};")

# COMMAND ----------

# すでに同名のテーブルが存在する場合は削除
sql(f"drop table if exists {case_bronze_table_name}")

# 生データを読み込み、デルタ・テーブルを作成して保存
raw_data_url = "https://raw.githubusercontent.com/hiouchiy/Pratical_RAG_Project/refs/heads/main/medallioncard/agent/cases.json"
!wget $raw_data_url -O /tmp/cases.json

unity_catalog_volume_path = f'/Volumes/{catalog}/{dbName}/{volume}/cases.json'
!cp /tmp/cases.json $unity_catalog_volume_path

spark.read.option("multiline","true").json(unity_catalog_volume_path).write.mode('overwrite').saveAsTable(case_bronze_table_name)

display(spark.table(case_bronze_table_name))

# COMMAND ----------

sql(f"DROP TABLE IF EXISTS {case_silver_table_name};")

sql(f"""
--インデックスを作成するには、テーブルのChange Data Feedを有効にします
CREATE TABLE IF NOT EXISTS {case_silver_table_name} (
  id BIGINT GENERATED BY DEFAULT AS IDENTITY,
  url STRING,
  case STRING
) TBLPROPERTIES (delta.enableChangeDataFeed = true); 
""")

spark.table(case_bronze_table_name).write.mode('overwrite').saveAsTable(case_silver_table_name)

display(spark.table(case_silver_table_name))

# COMMAND ----------

import mlflow.deployments
deploy_client = mlflow.deployments.get_deploy_client("databricks")

# カスタムEmbeddingモデル
response = deploy_client.predict(
  endpoint = embedding_endpoint_name, 
  inputs = {"inputs": ["Apache Sparkとはなんですか?", "ビッグデータとはなんですか？"]}
)
embeddings = [e for e in response.predictions]

print(embeddings)

# # Databricksの基盤モデル「databricks-bge-large-en」への切り替えも簡単
# embedding_endpoint_name = "databricks-bge-large-en"
# response = deploy_client.predict(
#   endpoint = embedding_endpoint_name, 
#   inputs = {"input": ["Apache Sparkとはなんですか?", "ビッグデータとはなんですか？"]}
# )
# embeddings = [e for e in response.data]

# print(embeddings)

# COMMAND ----------

from databricks.vector_search.client import VectorSearchClient

vsc = VectorSearchClient()

if VECTOR_SEARCH_ENDPOINT_NAME not in [e['name'] for e in vsc.list_endpoints().get('endpoints', [])]:
    vsc.create_endpoint(name=VECTOR_SEARCH_ENDPOINT_NAME, endpoint_type="STANDARD")

wait_for_vs_endpoint_to_be_ready(vsc, VECTOR_SEARCH_ENDPOINT_NAME)
print(f"Endpoint named {VECTOR_SEARCH_ENDPOINT_NAME} is ready.")

# COMMAND ----------

from databricks.sdk import WorkspaceClient
import databricks.sdk.service.catalog as c
import time

#インデックスの元となるテーブル
source_table_fullname = f"{catalog}.{db}.{case_silver_table_name}"

#インデックスを格納する場所
vs_index_fullname = f"{catalog}.{db}.{case_silver_table_name}_vs_index"

#すでに同名のインデックスが存在すれば削除
if index_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname):
  print(f"Deleting index {vs_index_fullname} on endpoint {VECTOR_SEARCH_ENDPOINT_NAME}...")
  vsc.delete_index(VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname)
  while True:
    if index_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname):
      time.sleep(1)
      print(".")
    else:      
      break

#インデックスを新規作成
print(f"Creating index {vs_index_fullname} on endpoint {VECTOR_SEARCH_ENDPOINT_NAME}...")
vsc.create_delta_sync_index(
  endpoint_name=VECTOR_SEARCH_ENDPOINT_NAME,
  index_name=vs_index_fullname,
  pipeline_type="TRIGGERED",
  source_table_name=source_table_fullname,
  primary_key="id",
  embedding_source_column="case",
  embedding_model_endpoint_name=embedding_endpoint_name
)

#インデックスの準備ができ、すべてエンベッディングが作成され、インデックスが作成されるのを待ちましょう。
wait_for_index_to_be_ready(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname)
print(f"index {vs_index_fullname} on table {source_table_fullname} is ready")

# COMMAND ----------


